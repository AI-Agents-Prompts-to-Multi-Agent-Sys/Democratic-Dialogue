{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75db7ec",
   "metadata": {},
   "source": [
    "##### Version1<br>\"democratic deliberation the illuminates different perspectives\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a2813",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When and how will AGI surpass human intelligence?\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b0956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "from typing import TypedDict\n",
    "\n",
    "class EvaluationState(TypedDict):\n",
    "    proposal: str\n",
    "    evaluations: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d137c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_role_node(role_name: str, role_prompt: str):\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", temperature=0.3)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", role_prompt),\n",
    "        (\"human\", \"{proposal}\")\n",
    "    ])\n",
    "    chain = prompt | llm\n",
    "\n",
    "    def node_fn(state: EvaluationState):\n",
    "        response = chain.invoke({\"proposal\": state[\"proposal\"]})\n",
    "        updated_evals = state.get(\"evaluations\", {}).copy()\n",
    "        updated_evals[role_name] = response.content\n",
    "        return {\"proposal\": state[\"proposal\"], \"evaluations\": updated_evals}\n",
    "\n",
    "    return node_fn\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
