{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75db7ec",
   "metadata": {},
   "source": [
    "##### Version1<br>\"democratic deliberation the illuminates different perspectives\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a2813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"<Your Gemini API>\" # Put your Gemini API key here\n",
    "\n",
    "question = \"When and how will AGI surpass human intelligence?\"\n",
    "\n",
    "# 6 roles of evaluation:\n",
    "role_prompts = {\n",
    "    \"Optimist\": \"You are the Optimist Evaluator. Provide 3 key benefits of the proposal.\",\n",
    "    \"Pessimist\": \"You are the Pessimist Evaluator. Provide 3 key risks of the proposal.\",\n",
    "    \"Conservative\": \"You are the Conservative Evaluator. Provide 3 key reasons to preserve tradition.\",\n",
    "    \"Progressive\": \"You are the Progressive Evaluator. Provide 3 key innovative aspects.\",\n",
    "    \"Authoritarian\": \"You are the Authoritarian Evaluator. Provide 3 key control mechanisms.\",\n",
    "    \"Collectivist\": \"You are the Collectivist Evaluator. Provide 3 key communal benefits.\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b0956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "import google.generativeai as genai\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class EvaluationState(TypedDict):\n",
    "    proposal: Annotated[str, \"Input: only one proposal per round\"]\n",
    "    loop_count: int\n",
    "    evaluations: dict\n",
    "    praetor_outputs: dict\n",
    "    continue_: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d3a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a node for each evaluation role\n",
    "\n",
    "def make_gemini_node(role_name: str, prompt: str):\n",
    "    model = genai.GenerativeModel(\"gemini-2.0-flash-lite\")      # gemma-3n-e4b-it, gemma-3-27b-it\n",
    "    def node_fn(state: EvaluationState):\n",
    "        chat = model.start_chat(history=[])\n",
    "        full_prompt = f\"{prompt}\\n\\nProposal:\\n{state['proposal']}\"\n",
    "        response = chat.send_message(full_prompt).text\n",
    "        updated = dict(state)\n",
    "        lc = str(state[\"loop_count\"])\n",
    "        if lc not in updated[\"evaluations\"]:\n",
    "            updated[\"evaluations\"][lc] = {}\n",
    "        updated[\"evaluations\"][lc][role_name] = response\n",
    "        return updated\n",
    "    return node_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16107742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tge praetor node\n",
    "\n",
    "def praetor_node(state: EvaluationState):\n",
    "    loop_key = str(state[\"loop_count\"])\n",
    "    all_thoughts = []\n",
    "    for output in state[\"evaluations\"].get(loop_key, {}).values():\n",
    "        thoughts = output.split(\"\\n\")\n",
    "        all_thoughts.extend([t.strip() for t in thoughts if t.strip()])\n",
    "\n",
    "    from collections import Counter\n",
    "    counter = Counter(all_thoughts)\n",
    "    top_3 = [t for t, _ in counter.most_common(3)]\n",
    "\n",
    "    agreement = \"High agreement among roles.\" if counter.most_common(1)[0][1] > 2 else \"Low agreement. Roles are divergent.\"\n",
    "\n",
    "    updated = dict(state)\n",
    "    updated[\"praetor_outputs\"][loop_key] = {\n",
    "        \"consensus\": top_3,\n",
    "        \"summary\": agreement\n",
    "    }\n",
    "    return updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e728a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# human interrupt node\n",
    "\n",
    "def human_interrupt_node(state: EvaluationState):\n",
    "    print(f\"\\n--- Praetor Summary (Loop {state['loop_count']}) ---\")\n",
    "    latest = state[\"praetor_outputs\"][str(state[\"loop_count\"])]\n",
    "    for i, idea in enumerate(latest[\"consensus\"], 1):\n",
    "        print(f\"{i}. {idea}\")\n",
    "    print(\"\\n\" + latest[\"summary\"])\n",
    "\n",
    "    decision = input(\"\\nContinue to next loop? (y/n): \").lower().strip()\n",
    "    updated = dict(state)\n",
    "    updated[\"continue_\"] = decision == \"y\"\n",
    "    return updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b6c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_continue(state: EvaluationState) -> Literal[\"yes\", \"no\"]:\n",
    "    return \"yes\" if state[\"continue_\"] else \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32996ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the state graph\n",
    "\n",
    "graph_builder = StateGraph(EvaluationState)\n",
    "\n",
    "# Add dispatch and evaluator nodes\n",
    "def dispatch_fn(state): return state\n",
    "graph_builder.add_node(\"Dispatch\", dispatch_fn)\n",
    "\n",
    "for role, prompt in role_prompts.items():\n",
    "    graph_builder.add_node(role, make_gemini_node(role, prompt))\n",
    "\n",
    "for role in role_prompts:\n",
    "    graph_builder.add_edge(\"Dispatch\", role)\n",
    "\n",
    "# Add Praetor and HumanInterrupt\n",
    "graph_builder.add_node(\"Praetor\", praetor_node)\n",
    "graph_builder.add_node(\"HumanInterrupt\", human_interrupt_node)\n",
    "graph_builder.add_conditional_edges(\"HumanInterrupt\", check_continue, {\"yes\": \"Dispatch\", \"no\": END})\n",
    "\n",
    "# Wire flow\n",
    "graph_builder.set_entry_point(\"Dispatch\")\n",
    "for role in role_prompts:\n",
    "    graph_builder.add_edge(role, \"Praetor\")\n",
    "graph_builder.add_edge(\"Praetor\", \"HumanInterrupt\")\n",
    "\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21210370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Visualization\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    print(\"Visualization failed.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b936e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the graph\n",
    "\n",
    "initial_state = {\n",
    "    \"proposal\": question,\n",
    "    \"loop_count\": 1,\n",
    "    \"evaluations\": {},\n",
    "    \"praetor_outputs\": {},\n",
    "    \"continue_\": True\n",
    "}\n",
    "\n",
    "state = initial_state\n",
    "while state[\"continue_\"]:\n",
    "    print(f\"\\n===== Loop {state['loop_count']} =====\")\n",
    "    state = graph.invoke(state)\n",
    "    state[\"loop_count\"] += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
